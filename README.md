# 🌟 DeepSeek R1 RAG智能问答系统 🚀

欢迎体验基于**RAG（检索增强生成）**架构的智能问答系统！📚 这个小助手不仅能读懂你的PDF，还能像个聪明的小伙伴一样回答你的问题！✨ 我们用Ollama作大脑，通过向量检索让文档问答变得更聪明、更高效！🧠
---

# 🎨 系统界面一览

看这界面，简洁又优雅！😎 用起来就像喝奶茶一样顺滑，点点鼠标就能和PDF聊起来！☕

---

## 1. ✨ 功能亮点

- 📖 **PDF上传+智能问答**：丢个PDF给我，我帮你挖出答案！
- 🔎 **超快向量检索**：用FAISS，找东西快到飞起！✈️
- 🤖 **Ollama大模型**：聪明又幽默的大脑后端！😜
- 🌍 **Web界面**：Gradio打造，简单好用，连奶奶都会！👵
- ⚡ **异步处理**：多任务齐飞，效率拉满！🚀
- 📋 **日志记录**：每一步都记下来，透明又靠谱！✅
- 🛡️ **Docker部署**：一键容器化，稳如老狗！🐶

---

## 2. 🏗️ 系统架构大揭秘

- **前端**：Gradio带你飞，Web界面美美哒！🌈
- **后端**：
  - Langchain：文档和LLM的“翻译官”！🌉
  - FAISS：向量数据库，检索速度快到你眨眼！⚡
  - Ollama：大语言模型，聪明得像个外星人！👽

---

## 3. ⚙️ 环境要求

- 🐳 Docker & Docker Compose（容器大师必备！）
- 🐍 Python 3.12+（新潮程序员的最爱！）
- 💾 24GB RAM（建议配置，越大越爽！）

---

## 4. 📂 项目结构一览

```shell
.
├── config/ # 配置文件，小秘密都在这！🔑
├── core/ # 核心模块，系统的“心脏”！❤️
│ ├── llm_service.py # 大模型服务，脑力担当！🧠
│ ├── pdf_processor.py # PDF处理大师！📜
│ └── vector_store.py # 向量存储，找东西超快！🔍
├── utils/ # 小工具箱，方便又实用！🛠️
├── fronted/ # Web界面，颜值担当！✨
├── logs/ # 日志文件，记录每一步精彩！📝
├── vector_db/ # 向量数据库，知识宝库！🏦
├── Dockerfile # Docker魔法书！📘
├── docker-compose.yml # 容器编排，团队配合无敌！🤝
└── requirements.txt # 依赖清单，缺一不可！📋
```

---

## 5. 🚀 启动你的智能助手

```bash
# 给脚本加点“权限魔法”
chmod +x start.sh stop.sh

# 一键启动，坐等起飞！
./start.sh

# 偷偷溜进Ollama容器，下载模型
docker exec -it ollama /bin/bash  
ollama run deepseek-r1:8b

# 玩够了？优雅关闭！
./stop.sh
```

---

## 6. 🌐 访问方式

打开浏览器，输入 `http://localhost:8888`，和你的RAG小助手愉快聊天吧！💬 简单到爆，连宠物狗都能学会！🐾

---

## 7. ⚡ 性能优化秘籍

- **异步处理**：多任务并行，像杂技大师一样灵活！🎪
- **向量检索**：优化到飞起，找答案比你找零食还快！🍕
- **文档分块**：切得刚刚好，效率Max！✂️
- **多线程**：PDF处理快到起飞，绝不拖后腿！🏃‍♂️

---

## 8. 🛠️ 部署小贴士

我们用**Docker Compose**打包了一切，简单两步走：

1. **RAGChat服务容器**：你的问答小助手！🤓
2. **Ollama服务容器**：大脑在线，随时待命！🧠

**网络配置**：
- 内部网络：`ragchat-network`（小团队的秘密基地！）
- 端口映射：`8888`（RAGChat），`11434`（Ollama）

部署完成后，喝杯咖啡，享受智能问答的乐趣吧！☕

---

# 🎉 快来试试吧！

这个RAG系统不仅聪明，还超有趣！快丢个PDF进来，看看它能给你讲出什么故事！📖✨


